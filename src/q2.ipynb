{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0aea754554291bc531c5082a1a77c0df7593cfc14c63ed34a0295729a0fffa55c",
   "display_name": "Python 3.9.2 64-bit ('CMT316': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "aea754554291bc531c5082a1a77c0df7593cfc14c63ed34a0295729a0fffa55c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "nltk.download(\"all\", quiet=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['business', 'tech', 'entertainment', 'sport', 'politics']\nbbc/business\nbbc/tech\nbbc/entertainment\nbbc/sport\n'utf-8' codec can't decode byte 0xa3 in position 257: invalid start byte for bbc/sport/199.txt\nbbc/politics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def load_corpus(folder):\n",
    "    corpus = []\n",
    "    for root, dirs, files in os.walk(folder, topdown=False):\n",
    "        for name in files:\n",
    "            try:\n",
    "                with open(os.path.join(root, name), \"r\") as fp:\n",
    "                    corpus.append(fp.read())\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(e.__str__(), \"for\", os.path.join(root, name))\n",
    "    return corpus\n",
    "\n",
    "def load_corpuses(folder):\n",
    "    sub_folders = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        if dirs:\n",
    "            for dir_ in dirs:\n",
    "                sub_folders.append(dir_)\n",
    "\n",
    "    corpuses = {}\n",
    "    print(sub_folders)\n",
    "    for sub_folder in sub_folders:\n",
    "        print(os.path.join(folder, sub_folder))\n",
    "        corpuses[sub_folder] = load_corpus(os.path.join(folder, sub_folder))\n",
    "    return corpuses\n",
    "\n",
    "corpuses = load_corpuses(\"bbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "tfid = TfidfTransformer()\n",
    "\n",
    "all_ = []\n",
    "for corpus in corpuses:\n",
    "    all_ += corpuses[corpus]\n",
    "\n",
    "vectorizer.fit(all_)\n",
    "tfid.fit(vectorizer.transform(all_))\n",
    "\n",
    "# x = vectorizer.transform(corpuses[\"tech\"])\n",
    "# vectorizer.vocabulary_.get('Sony')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a6570b556074d01aaa842867191211b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/510 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "561ff204de5a4012b4189f876ee7f833"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/401 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0eb47472fd24e5598e739a5edc733e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/386 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4849c938dbb0428694421b8e37943015"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/510 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "988eac88d5254a8c98648edd267097d7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/417 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a0a112ea6674c2aa563b9e1fea47eb6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import math\n",
    "x = []\n",
    "y =[]\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "entity_types = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "entity_types.fit(['CARDINAL', 'PERSON', 'GPE', 'MONEY', 'ORG', 'ORDINAL', 'WORK_OF_ART', 'NORP', 'PERCENT', 'DATE', 'LANGUAGE', 'FAC', 'LOC', 'TIME', 'PRODUCT', 'EVENT', 'QUANTITY', 'LAW'])\n",
    "for corpus in tqdm(corpuses):\n",
    "    for story in tqdm(corpuses[corpus]):\n",
    "        analysed = nlp(story)\n",
    "        # print(entity_types.transform([tag.label_ for tag in analysed.ents]).toarray()[0])\n",
    "        # print(vectorizer.transform([story]).toarray()[0])\n",
    "        # print(list(tfid.transform(vectorizer.transform([story])).toarray()[0]))\n",
    "        x.append(list(vectorizer.transform([story]).toarray()[0]) + \n",
    "                 list(entity_types.transform([tag.label_ for tag in analysed.ents]).toarray()[0]) +\n",
    "                 list(tfid.transform(vectorizer.transform([story])).toarray()[0])\n",
    "                )\n",
    "        # x.append(tfid.transform(vectorizer.transform([story])).toarray()[0])\n",
    "\n",
    "        y.append(corpus)\n",
    "\n",
    "import random\n",
    "\n",
    "c = list(zip(x, y))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "x, y = zip(*c)\n",
    "# pprint(x[:3])\n",
    "# pprint(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "fs_sentanalysis=SelectKBest(chi2, k=500).fit(x, y)\n",
    "x_chi = fs_sentanalysis.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_chi' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f59176d46461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_chi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_chi' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(x), len(x_chi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dataset_full=len(x_chi)\n",
    "size_test=int(round(size_dataset_full*0.2,0))\n",
    "\n",
    "list_test_indices=random.sample(range(size_dataset_full), size_test)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for i,example in enumerate(x_chi):\n",
    "  if i in list_test_indices:\n",
    "      test_x.append(example)\n",
    "      test_y.append(y[i])\n",
    "  else:\n",
    "      train_x.append(example)\n",
    "      train_y.append(y[i])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y + test_y)\n",
    "train_y = le.transform(train_y)\n",
    "test_y = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 4 2 3 2 1 0 0 4 0 1 0 3 2 0 2 4 0 3 4 3 3 3 3 0 4 0 4 0 2 2 2 3 1 0 1\n 0 3 4 0 0 2 0 1 3 4 0 0 3 3 0 0 3 2 4 0 1 0 0 4 1 3 0 1 4 0 4 4 1 1 4 2 3\n 4 0 4 1 0 0 1 3 2 2 2 0 2 1 4 4 4 0 4 2 4 1 4 0 3 2 3 3 4 0 0 3 0 3 4 3 0\n 2 2 0 2 3 0 3 2 2 3 0 4 1 3 2 0 0 3 1 3 3 1 4 1 4 4 3 0 0 4 4 2 4 3 4 2 3\n 1 0 1 1 0 3 2 3 2 3 3 0 0 1 4 1 0 3 0 0 1 1 4 1 3 1 3 3 3 0 3 0 3 2 0 0 4\n 0 3 1 1 4 4 4 4 4 2 4 3 2 2 1 0 3 0 3 4 0 3 1 0 3 0 2 0 1 2 3 4 0 1 3 1 0\n 1 3 1 3 1 2 1 0 1 0 3 4 3 3 2 0 2 1 1 0 0 2 3 3 1 0 2 3 4 3 3 0 4 4 3 2 3\n 1 2 4 0 3 3 4 4 4 2 0 0 4 0 0 0 0 1 3 3 2 3 0 2 0 2 0 0 0 4 3 3 4 1 1 4 4\n 2 2 3 0 0 3 0 1 1 2 2 0 1 0 2 2 0 3 0 1 3 4 4 2 1 3 3 2 3 3 0 2 4 3 0 2 0\n 1 0 4 1 0 0 0 1 3 0 2 0 0 0 2 1 1 0 1 3 1 0 2 3 1 3 4 2 1 3 3 4 3 0 4 4 2\n 4 3 4 0 0 3 4 1 1 1 1 0 0 2 4 3 0 2 3 1 3 0 4 1 4 4 4 0 3 2 2 3 3 3 4 4 4\n 0 1 0 0 1 2 4 0 1 3 2 2 2 3 0 0 0 0 0 2 3 2 0 4 0 4 1 3 2 2 1 3 2 1 2 0 0\n 3]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "svm_clf=make_pipeline(StandardScaler(), svm.SVC(cache_size=10000, decision_function_shape='ovo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(cache_size=10000, decision_function_shape='ovo'))])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "svm_clf.fit(train_x_chi, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 58572 features, but StandardScaler is expecting 500 features as input.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7c949a519c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_text_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/CMT316-_3fUo8fQ/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CMT316-_3fUo8fQ/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CMT316-_3fUo8fQ/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[1;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CMT316-_3fUo8fQ/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CMT316-_3fUo8fQ/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 58572 features, but StandardScaler is expecting 500 features as input."
     ]
    }
   ],
   "source": [
    "Y_text_predictions = svm_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, Y_text_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "England centre Emily Scarratt says having a final in this year's reformatted Women's Six Nations could help the side's World Cup preparations.\n",
    "\n",
    "Because of the coronavirus pandemic, teams will have two pool games and a final rather than playing all of the other five teams.\n",
    "\n",
    "Covid-19 also forced the postponement of the World Cup until 2022.\n",
    "\n",
    "\"You do not get a final very often in our calendar,\" Scarratt told BBC Radio 5 Live's Rugby Union Weekly.\n",
    "\n",
    "Listen to Rugby Union Weekly: Danny's coat, Scaz and Liar's dice\n",
    "Shaunagh Brown column: Wasted chances, fantasy rugby and the importance of good hair\n",
    "The 31-year-old - who captained England to a 52-10 win against Scotland on Saturday in the absence of Sarah Hunter - added that she \"was not sure\" about the new format initially.\n",
    "\n",
    "\"I am a traditionalist. I like the format of playing five games,\" she continued.\n",
    "\n",
    "\"But we now get the opportunity to play a final. Sometimes when you get to that moment it is a World Cup and all of a sudden a big deal.\"\n",
    "\n",
    "England's opening victory puts them top of Pool A with a game in Italy to come on Saturday.\n",
    "\n",
    "After France's dominant 53-0 defeat of Wales in Pool B, all signs currently point to a final between England and Les Bleues, to be shown live on BBC Two on 24 April.\n",
    "\n",
    "Aside from the benefits of a final, Scarratt is glad that the Women's Six Nations is taking place in a different window to the men's tournament.\n",
    "\n",
    "\"We're not having to compete with men's kick-off times or a load of people watching the [men's] game at Twickenham and a much lower percentage watching the [women's] game at the Stoop,\" she explained.\n",
    "\n",
    "\"That is the exciting bit for me. It would be great to have crowds to quantify what that would look like but at the same time it is really important for us to stand on our own two feet this time around.\"\n",
    "\"\"\"\n",
    "\n",
    "analysed = nlp(story)\n",
    "genre = le.inverse_transform([svm_clf.predict([list(vectorizer.transform([story]).toarray()[0]) + \n",
    "                                               list(entity_types.transform([tag.label_ for tag in analysed.ents]).toarray()[0]) +\n",
    "                                               list(tfid.transform(vectorizer.transform([story])).toarray()[0])\n",
    "                             ])[0]])[0]\n",
    "\n",
    "display(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}